{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: create a file doc for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/Airbnb_Texas_Rentals.csv\", 'r', encoding = \"utf8\") as f:\n",
    "    with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/updated_test.csv\",'w', encoding = \"utf8\") as f1:\n",
    "        next(f) # skip first row\n",
    "        for line in f:\n",
    "            f1.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/updated_test.csv\", 'r', encoding = \"utf8\") as csvfile: \n",
    "    #opening the original file\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    \n",
    "    with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/Airbnb_Texas_Rentals.tsv\", 'w', encoding = \"utf8\") as tsvfile: \n",
    "        #opening a new file for writing called newfile \n",
    "        csv_writer = csv.writer(tsvfile, delimiter = '\\t')\n",
    "    \n",
    "        for line in csv_reader:\n",
    "            csv_writer.writerow(line[1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/Airbnb_Texas_Rentals.tsv\", encoding = \"utf8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        with open(\"doc_{}.tsv\".format(str(i+1)), \"w\", ) as doc:\n",
    "            doc.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - removing stopwords and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/milpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = stopwords.words('english') # get english stop words\n",
    "print(stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'is', \"n't\", 'on', 'the', 'table']\n"
     ]
    }
   ],
   "source": [
    "prova = \"the cat isn't on the table\"\n",
    "words = word_tokenize(prova)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', \"n't\", 'table']\n"
     ]
    }
   ],
   "source": [
    "prova1 = [w for w in words if w.lower() not in stopwords]\n",
    "print(prova1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_1.tsv' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_2.tsv' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_3.tsv' mode='r' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_4.tsv' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    with open(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_\" + str(i) + \".tsv\", \"r\") as f:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo un numpy per ogni tsv \n",
    "doc_1 = np.loadtxt(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_1.tsv\", delimiter='\\t', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasformo in lista\n",
    "doc_1 = doc_1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuovo il carattere \\\\n e aggiungo uno spazio\n",
    "doc_1[4] = doc_1[4].replace(\"\\\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$27',\n",
       " '2',\n",
       " 'Humble',\n",
       " 'May 2016',\n",
       " 'Welcome to stay in private room with queen bed and detached private bathroom on the second floor. Another private bedroom with sofa bed is available for additional guests. 10$ for an additional guest. 10min from IAH airport Airport pick-up/drop off is available for $10/trip.',\n",
       " '30.0201379199512',\n",
       " '-95.2939960042513',\n",
       " '2 Private rooms/bathroom 10min from IAH airport',\n",
       " 'https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome', 'to', 'stay', 'in', 'private', 'room', 'with', 'queen', 'bed', 'and', 'detached', 'private', 'bathroom', 'on', 'the', 'second', 'floor', 'Another', 'private', 'bedroom', 'with', 'sofa', 'bed', 'is', 'available', 'for', 'additional', 'guests', '10$', 'for', 'an', 'additional', 'guest', '10min', 'from', 'IAH', 'airport', 'Airport', 'pick', 'up', 'drop', 'off', 'is', 'available', 'for', '$10', 'trip']\n"
     ]
    }
   ],
   "source": [
    "# ora voglio togliere le stopwords e la punteggiatura dalla descrizione\n",
    "tokenizer = RegexpTokenizer(\"[\\w'\\$]+\")\n",
    "words_1 = tokenizer.tokenize(doc_1[4])\n",
    "print(words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome', 'stay', 'private', 'room', 'queen', 'bed', 'detached', 'private', 'bathroom', 'second', 'floor', 'Another', 'private', 'bedroom', 'sofa', 'bed', 'available', 'additional', 'guests', '10$', 'additional', 'guest', '10min', 'IAH', 'airport', 'Airport', 'pick', 'drop', 'available', '$10', 'trip']\n"
     ]
    }
   ],
   "source": [
    "aa = [w for w in words_1 if w.lower() not in stopwords]\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcom', 'stay', 'privat', 'room', 'queen', 'bed', 'detach', 'privat', 'bathroom', 'second', 'floor', 'anoth', 'privat', 'bedroom', 'sofa', 'bed', 'avail', 'addit', 'guest', '10$', 'addit', 'guest', '10min', 'iah', 'airport', 'airport', 'pick', 'drop', 'avail', '$10', 'trip']\n"
     ]
    }
   ],
   "source": [
    "# stamming\n",
    "st = PorterStemmer()\n",
    "aa = [st.stem(word) for word in aa]\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-265-c2d0f235d6c3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-265-c2d0f235d6c3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \"doc_\"+str(i) = np.loadtxt(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_\" + str(i) + \".tsv\", delimiter='\\t', dtype='str')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    \"doc_%s\"%i = np.loadtxt(\"/Users/milpro/Desktop/Universita/ADM_Aris/HW3/doc_tsv/doc_\" + str(i) + \".tsv\", delimiter='\\t', dtype='str')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
